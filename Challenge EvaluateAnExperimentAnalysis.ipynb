{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The Sith Lords are concerned that their recruiting slogan, \"Give In to Your Anger,\" isn't very effective. Darth Vader develops an alternative slogan, \"Together We Can Rule the Galaxy.\" They compare the slogans on two groups of 50 captured droids each. In one group, Emperor Palpatine delivers the \"Anger\" slogan. In the other, Darth Vader presents the \"Together\" slogan. 20 droids convert to the Dark Side after hearing Palpatine's slogan, while only 5 droids convert after hearing Vader's. The Sith's data scientist concludes that \"Anger\" is a more effective slogan and should continue to be used.<br>\n",
    "\n",
    "A. We have 100 droids in total. Right after the respective slogans, we know 20 converted to \"Anger\" slogan and 5 converted to \"Together\". It is incorrect to conclude that \"Anger\" is more effective since this conversion contributes just to 25% of our population and it was done right after speech. Only after some time and after the majority (more than 50% of total droids) convert, we can do any conclusion. This is a bias done by people running study which is Sith's data scientist in this case.<br><br>\n",
    "\n",
    "2. In the past, the Jedi have had difficulty with public relations. They send two envoys, Jar Jar Binks and Mace Windu, to four friendly and four unfriendly planets respectively, with the goal of promoting favorable feelings toward the Jedi. Upon their return, the envoys learn that Jar Jar was much more effective than Windu: Over 75% of the people surveyed said their attitudes had become more favorable after speaking with Jar Jar, while only 65% said their attitudes had become more favorable after speaking with Windu. This makes Windu angry, because he is sure that he had a better success rate than Jar Jar on every planet. The Jedi choose Jar Jar to be their representative in the future.<br>\n",
    "\n",
    "A. Looks like its a case of Simpson's paradox. We need to perform the survey for each of the 8 individual planets to check the real survey results. The result has the sample bias or collection bias since Jar Jar was send to friendly planet where the favourism expected would be more and Windu was sent to unfriendly planet where favourism would be less. <br><br>\n",
    "\n",
    "3. A company with work sites in five different countries has sent you data on employee satisfaction rates for workers in Human Resources and workers in Information Technology. Most HR workers are concentrated in three of the countries, while IT workers are equally distributed across worksites. The company requests a report on satisfaction for each job type. You calculate average job satisfaction for HR and for IT and present the report.<br>\n",
    "\n",
    "A. Since the concentrations of HR workers are more in 3 countries, it is likely that it is less in other two countries. If we want to truely compare the avg of satisfaction report, we need to do it for individiual regions and choose samples which equal number of HR and IT workers, else just report the individual Dept (HR or IT) satisfaction report and provide the average for each of the countries. The lurking variable here is the location.<br><br>\n",
    "\n",
    "4. When people install the Happy Days Fitness Tracker app, they are asked to \"opt in\" to a data collection scheme where their level of physical activity data is automatically sent to the company for product research purposes. During your interview with the company, they tell you that the app is very effective because after installing the app, the data show that people's activity levels rise steadily.<br>\n",
    "\n",
    "A. This conclusion is biased since it is based on people opting in for data collection. Not all who install the app will opt for data collection. Most of the time people who are physically active whould want to opt in for these data collections. So if data collection would be compulsory after installation of the app then the companies assumptions could make sense. This seems like a context bias.<br><br>\n",
    "\n",
    "5. To prevent cheating, a teacher writes three versions of a test. She stacks the three versions together, first all copies of Version A, then all copies of Version B, then all copies of Version C. As students arrive for the exam, each student takes a test. When grading the test, the teacher finds that students who took Version B scored higher than students who took either Version A or Version C. She concludes from this that Version B is easier, and discards it.<br>\n",
    "\n",
    "A. Is is a biased way to arrange one stack one top of each other. For tests to be more effective, teacher should have shuffled the tests randomly so that no neighbour share the same version of the test. Also we need to consider the fact that students who tend to cheat must be put in a position that can be easily monitored."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
